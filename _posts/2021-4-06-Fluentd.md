---
category: Notes
url_path: '/notes'
title: 'Fluentd'

layout: null
---

## Description
+ Acts as a shipper or collector. 
  + As the shipper, it forwards log data to Elasticsearch
  + As a collector, it collects and forwards logs to shipper
  
### 1. Configuration

+ 1.1 fluent.conf - Collect logs from "/var/log/containers/*.log"
<pre><code class="language-plaintext"><source>type tail
  path /var/log/containers/*.log
  pos_file /var/log/es-containers.log.pos
  time_format %Y-%m-%dT%H:%M:%S.%N
  tag kubernetes.*
  format json
  read_from_head true
  keep_time_key true
</source>

<filter kubernetes.**>
  type kubernetes_metadata
</filter>

<match **>
  type elasticsearch
  log_level info
  include_tag_key true
  host "#{ENV['ES_HOST']}"
  port "#{ENV['ES_PORT']}"
  logstash_format true
  flush_interval 5s
  # Never wait longer than 5 minutes between retries.
  max_retry_wait 60
  # Disable the limit on the number of retries (retry forever).
  disable_retry_limit
  time_key time
  reload_connections false
</match>
</code></pre>

### 2. Deployment step

+ 2.1  Create a new Service account for Fluentd (Create an identity)

<pre><code class="language-plaintext">apiVersion: v1
   kind: ServiceAccount
   metadata:
     name: fluentd
   namespace: kube-system
</code></pre>

+ 2.2 Grant Fluentd permissions to read, list, and watch pods and namespaces in your Kubernetes cluster.

<pre><code class="language-plaintext">apiVersion: rbac.authorization.k8s.io/v1beta1
   kind: ClusterRole
   metadata:
     name: fluentd
     namespace: kube-system
   rules:
   - apiGroups:
   - ""
     resources:
     - pods
     - namespaces
     verbs:
     - get
     - list
     - watch
</code></pre>

+ 2.3 ClusterRoleBinding bind the Fluentd ServiceAccount to stated permissions in 2.2
<pre><code class="language-plaintext">kind: ClusterRoleBinding
   apiVersion: rbac.authorization.k8s.io/v1beta1
   metadata:
     name: fluentd
   roleRef:
     kind: ClusterRole
     name: fluentd
     apiGroup: rbac.authorization.k8s.io
   subjects:
   - kind: ServiceAccount
     name: fluentd
     namespace: kube-system
</code></pre>

+ 2.4 Deploy as a DaemonSet
<pre><code class="language-plaintext">apiVersion: extensions/v1beta1
   kind: DaemonSet
   metadata:
     name: fluentd
     namespace: kube-system
     labels:
       k8s-app: fluentd-logging
       version: v1
       kubernetes.io/cluster-service: "true"
   spec:
     template:
       metadata:
         labels:
           k8s-app: fluentd-logging
           version: v1
           kubernetes.io/cluster-service: "true"
       spec:
         serviceAccount: fluentd
         serviceAccountName: fluentd
         tolerations:
         - key: node-role.kubernetes.io/master
           effect: NoSchedule
         containers:
         - name: fluentd
           image: fluent/fluentd-kubernetes-daemonset:elasticsearch
           env:
           - name:  FLUENT_ELASTICSEARCH_HOST
             value: "f505e785.qb0x.com"
           - name:  FLUENT_ELASTICSEARCH_PORT
             value: "30216"
           - name: FLUENT_ELASTICSEARCH_SCHEME
             value: "https"
           - name: FLUENT_UID
             value: "0"
           # X-Pack Authentication
           # =====================
           - name: FLUENT_ELASTICSEARCH_USER
             value: "abf54990f0a286dc5d76"
           - name: FLUENT_ELASTICSEARCH_PASSWORD
             value: "75c4bd6f7b"
           resources:
             limits:
               memory: 200Mi
             requests:
               cpu: 100m
               memory: 200Mi
           volumeMounts:
           - name: varlog
             mountPath: /var/log
           - name: varlibdockercontainers
             mountPath: /var/lib/docker/containers
             readOnly: true
         terminationGracePeriodSeconds: 30
         volumes:
         - name: varlog
           hostPath:
             path: /var/log
         - name: varlibdockercontainers
           hostPath:
             path: /var/lib/docker/containers
</code></pre>

### 3. How application log data?
+ 3.1 Write to files
 + Cons:  
  1. Difficult to analyze by viewing the log files
  2. Different format
<br/>
+ 3.2 Log directly into Database
 + Cons:
  1. Each application must be configured with DB connection
<br/>
+ 3.3 Fluentd - Unified logging layer
 + Pros: 
  1. Collect logs from different data sources (e.g. app log, system log, database log, access log)
  2. The source can be in different formats
  3. Enrich the log content by specifying the pod name, namespace, container name
  4. Send to destination (e.g. Elastic Search, MongoDB, Kafka)
  5. Support built-in reliability - Save data on HDD until the porcessing data is sent to the configured output destination 
  6. i.e. Data still exists after restart and no additional storage is required
  7. Auto retry sending the processing data to output destination
  8. Support clustering to provide HA
 <br/>
 
 + 3.4 Fluentd Process
 ![fluentd_process](https://github.com/rayyiu002/ray_TechWorld/blob/gh-pages/image/fluentd_process.png?raw=true)
  
### Reference
+ [https://medium.com/kubernetes-tutorials/cluster-level-logging-in-kubernetes-with-fluentd-e59aa2b6093a](https://medium.com/kubernetes-tutorials/cluster-level-logging-in-kubernetes-with-fluentd-e59aa2b6093a)
+ [https://youtu.be/5ofsNyHZwWE](https://youtu.be/5ofsNyHZwWE)